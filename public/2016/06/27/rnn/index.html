<!DOCTYPE html>
<html lang="zh-cn,en,default">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Liyan Jiang">





<title>Introduction to RNNs | Hardboiled Wonderland</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
    


<meta name="generator" content="Hexo 6.2.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Liyan&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/categories">Categories</a>
                
                    <a class="menu-item" href="/tags">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Liyan&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/categories">Categories</a>
                
                    <a class="menu-item" href="/tags">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Introduction to RNNs</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Liyan Jiang</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">六月 27, 2016&nbsp;&nbsp;15:02:57</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/Deep-Learning/">Deep Learning</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h3 id="Abstract-简介"><a href="#Abstract-简介" class="headerlink" title="Abstract | 简介"></a>Abstract | 简介</h3><h4 id="Language-Model-语言模型"><a href="#Language-Model-语言模型" class="headerlink" title="Language Model | 语言模型"></a>Language Model | 语言模型</h4><p>语言模型主要解决两件事</p>
<ul>
<li>能够对计算机生成的句子进行打分，分数高低取决于这个句子有多大概率在现实中出现。分数作为一种语法和语义上的度量</li>
<li>能够产生新的句子。比如用莎士比亚作品作为语料库，可以产生莎士比亚文风的句子。</li>
</ul>
<h4 id="Recurrent-Nerual-Network-循环神经网络"><a href="#Recurrent-Nerual-Network-循环神经网络" class="headerlink" title="Recurrent Nerual Network | 循环神经网络"></a>Recurrent Nerual Network | 循环神经网络</h4><p>关于统计语言模型， Bengio 曾提出过一个使用定长文本训练的前馈神经网络。但这个模型的主要问题是前馈网络依赖于一个预设的文本长度，不能针对不同语境作出动态变化。循环神经网络针对这点作出改进：RNN 不限制文本的长度，而且文本信息能够在网络中循环任意时间。</p>
<p>RNN 的主要思想是充分利用序列化信息之间时间上的关联。传统神经网络将所有输入信息作为相互独立的信息来看待，但在很多情况下（尤其是自然语言处理的问题上）并不是个好的想法。因为语境信息对于语言模型是至关重要的，一个词在某个位置出现的概率很大程度上受前文中其他词的影响。RNN 之所以叫循环神经网络是因为它对序列中每个词的处理是基于前面词的状态。可以理解为 RNN 是一个带有记忆的模型，它能够缓存之前的运算结果，这些状态结果会一直影响接下来的神经元运算。理论上 RNN 能够充分利用任意长度序列的信息，但出于对效率因素的考虑只回看若干步。</p>
<p><a target="_blank" rel="noopener" href="https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/">trask 博客</a>中的这个 gif 图片能够很直观得看出 RNN 的运行过程。</p>
<p><img src="/uploads/recurrence_gif.gif" alt="RNN_GIF"><span class="my-image-caption">RNN_GIF</span></p>
<p>图中展示了 4 个时间步 (timestep) 中隐层 (hidden layer) 的变化。第一个时间步中隐层的计算完全依赖于输入；第二个时间步中隐层的输入来源于第一个隐层的输出和第二个时间步的输入。到了第四个时间步，隐层已经包含了所有输入信息。到第五个时间步，隐层就要决定哪些信息要留下，哪些信息要被覆盖。因此隐层节点越多就能记住更长的时间段内的信息，隐层节点数量意味着循环神经网络的记忆容量。</p>
<p>这样的架构中，输入不仅仅是单纯的输入，输入信息不停地更新 RNN 的 “memory”， 输出是基于某个状态下的 “memory”. 即便某个时间步内没有任何输入, memory 也会随着时间动态发生变化。</p>
<p>先通过一个最基础的 RNN 了解一下它的架构。 Simple recurrent neural network (or Elman Network）</p>
<table>
<thead>
<tr>
<th>符号表示</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>$x(t)$</td>
<td>t 时间步的输入信息</td>
</tr>
<tr>
<td>$y(t)$</td>
<td>t 时间步的输出信息</td>
</tr>
<tr>
<td>$s(t)$</td>
<td>t 时间步的隐层（神经网络的状态）</td>
</tr>
<tr>
<td>$U$</td>
<td>隐层和隐层之间的传导矩阵 synapse_h</td>
</tr>
<tr>
<td>$V$</td>
<td>隐层和输出层之间的传导矩阵 synapse_1</td>
</tr>
<tr>
<td>$f(z)$</td>
<td>sigmoid 激活函数</td>
</tr>
<tr>
<td>$g(z_m)$</td>
<td>softmax 函数</td>
</tr>
</tbody></table>
<p>$$ x(t) &#x3D; w(t) + s(t-1) $$</p>
<p>$$ s_j(t) &#x3D; f\left(\sum_i x_i(t)u_ij \right)$$</p>
<p>$$ y_k(t) &#x3D; g\left(\sum_j s_j(t)v_kj \right)$$</p>
<p>$$ s.t. f(z) &#x3D; \frac{1}{1+e^{-z}} , g(z_m) &#x3D; \frac{e^{z_m}}{\sum_{k}e^{z_k}}$$</p>
<p>$s(0)$ 被初始化为值很小的向量，比如 0.1 。处理大量数据时初始化不是关键因素。隐层节点数量大约在 30-500 之间，反应了训练数据的数量。</p>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>神经网络大约要经过 10-20 个 epoch 才能达到比较好的收敛效果。BP 算法和 SGD(Stochastic Gradient Descent) 是比较常见的训练方法。设置 learning rate 为 0.1, 每完成一个 epoch 就要在验证集上进行测试，通过观察验证集的对数似然来判断模型是否收敛。如果模型没有显著提高，就将 learning rate 减半，接着进行下一个 epoch .</p>
<h4 id="Backpropagation-Through-Time-BPTT"><a href="#Backpropagation-Through-Time-BPTT" class="headerlink" title="Backpropagation Through Time (BPTT)"></a>Backpropagation Through Time (BPTT)</h4><p>gif 动态图来自<a target="_blank" rel="noopener" href="https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/">trask 博客</a></p>
<p><img src="/uploads/backprop_through_time.gif" alt="bptt"><span class="my-image-caption">bptt</span></p>
<p>BPTT 是 BP 算法针对循环神经网络的一个改进版本。BPTT 的参数被所有时间步共享。每个输出的梯度依赖于之前的时间步，其实就是对应微积分中的链式法则。例如为了计算 $t &#x3D; 4$ 时的梯度，需要反向传播 3 次更新权重。BPTT 算法仍有不能解决的问题，比如词汇间的长期依赖(long-term dependency). 两个词隔得很远，但它们之间确有联系。在时间步到达第二个词的时候，第一个词已经被遗忘了。这就是所谓的梯度消失&#x2F;梯度爆炸 (vanishing&#x2F;exploding gradient) 问题。针对这个问题已经有了好的解决方法，如 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM</a>.  LSTM 的架构原则上和一般 RNN 没有什么不同，但在隐层的计算上用了一些技巧，能够选择哪些重要的信息值得记忆。对于捕获词汇间的长期依赖有很大的贡献。</p>
<h3 id="Reference-参考资料"><a href="#Reference-参考资料" class="headerlink" title="Reference | 参考资料"></a>Reference | 参考资料</h3><p><a target="_blank" rel="noopener" href="http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf">Mikolov: Recurrent neural network based language model</a><br><a target="_blank" rel="noopener" href="http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_presentation_rnnlm-extension.pdf">Mikolov: Extensions of recurrent neural network language model</a><br><a target="_blank" rel="noopener" href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">WildML:Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs</a><br><a target="_blank" rel="noopener" href="https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/">trask: Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN)</a></p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Liyan Jiang</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://gnoluna.github.io/blog/2016/06/27/rnn/">http://gnoluna.github.io/blog/2016/06/27/rnn/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span></span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/Deep-Leaning/"># Deep Leaning</a>
                    
                        <a href="/tags/RNN/"># RNN</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2016/07/03/lstm/">论文阅读: Long Short-Term Memory Based Recurrent Neural Network Architectures for Large Vocabulary Speech Recognition</a>
            
            
            <a class="next" rel="next" href="/2016/06/23/drwpc/">论文阅读: Distributed Representation of Words and Phrases and their Compositionality</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Liyan Jiang | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>